{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Model Activities.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mFshqH8j6Wj"
      },
      "source": [
        "#importing libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "import pickle\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score,accuracy_score,confusion_matrix"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKqgQY9Tq6Jm",
        "outputId": "6de0bbae-03a1-4420-b610-139812cb3ffc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Tv9O-8Bj6Wv"
      },
      "source": [
        "activities=[\"climbingdown\",\"climbingup\",\"jumping\",\"lying\",\"running\",\"sitting\",\"standing\",\"walking\"]\n",
        "location='/content/drive/MyDrive/Major_Project/clean_data.csv'\n",
        "data=pd.read_csv(location)\n",
        "data.drop(data.columns[[0]],axis=1,inplace=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nyDolChj6Wx"
      },
      "source": [
        "def Range(a):\n",
        "    return a.max()-a.min();"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYTQxEQEj6Wy"
      },
      "source": [
        "def plot_confusion_matrix(cm,classes,normalize=False,title='Confusion Matrix',cmap='YlOrRd'):\n",
        "    plt.rcParams.update({'font.size': 11})\n",
        "    plt.figure(figsize=(25,10),)\n",
        "    plt.imshow( cm,interpolation='nearest',cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),horizontalalignment=\"center\",color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout();"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAxwNjbNj6Wz"
      },
      "source": [
        "def implement_model(model,title):\n",
        "    model.fit(X_train,Y_train)\n",
        "    Y_predicted_train=model.predict(X_train)\n",
        "    Y_predicted_validate=model.predict(X_validate)\n",
        "    print(f'Training F1 score is: {f1_score(Y_train,Y_predicted_train,average=\"macro\"):.3f}')\n",
        "    print(f'Validation F1 score is: {f1_score(Y_validate,Y_predicted_validate,average=\"macro\"):.3f}')\n",
        "    print(f'Training Accuracy is: {accuracy_score(Y_train,Y_predicted_train):.3f}')\n",
        "    print(f'Validation Accuracy is: {accuracy_score(Y_validate,Y_predicted_validate):.3f}')\n",
        "    np.set_printoptions(precision=2)\n",
        "    cm=confusion_matrix(Y_validate,Y_predicted_validate)\n",
        "    plt.figure()\n",
        "    plot_confusion_matrix(cm,classes=activities,title='Validation Confusion Matrix for '+title);"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwWwPTwVj6W1"
      },
      "source": [
        "range_sample=data.groupby(['Activity','Subject','Sample_Num']).apply(Range).add_prefix('range_')\n",
        "stdev_sample=data.groupby(['Activity','Subject','Sample_Num']).std().add_prefix('std_')\n",
        "mean_sample=data.groupby(['Activity','Subject','Sample_Num']).mean().add_prefix('mean_')\n",
        "total_data=pd.concat([stdev_sample,mean_sample,range_sample],axis=1)\n",
        "total_data.reset_index(inplace=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cx5jnNCCj6W2"
      },
      "source": [
        "columns=[\n",
        "       'std_attr_x_gyro', 'std_attr_y_gyro', 'std_attr_z_gyro',\n",
        "         'std_attr_x_acc', 'std_attr_y_acc', 'std_attr_z_acc', \n",
        "         'mean_attr_x_gyro', 'mean_attr_y_gyro', 'mean_attr_z_gyro', \n",
        "         'mean_attr_x_acc', 'mean_attr_y_acc', 'mean_attr_z_acc',\n",
        "         'range_attr_x_gyro', 'range_attr_y_gyro','range_attr_z_gyro', \n",
        "         'range_attr_x_acc', 'range_attr_y_acc', 'range_attr_z_acc']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJbciykUj6W2"
      },
      "source": [
        "train_temp=total_data.Subject<=3\n",
        "validate_temp=total_data.Subject==4\n",
        "X_train=total_data[columns][train_temp]\n",
        "X_validate=total_data[columns][validate_temp]\n",
        "Y_train=total_data.Activity[train_temp]\n",
        "Y_validate=total_data.Activity[validate_temp]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eMYta_Zj6W3",
        "outputId": "20df4330-08dc-42da-9356-c4ae79ba4623",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "scaler=StandardScaler()\n",
        "X_train=scaler.fit_transform(X_train)\n",
        "X_validate=scaler.fit_transform(X_validate)\n",
        "print('X_train->',X_train.shape)\n",
        "print('X_validate->',X_validate.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train-> (6386, 18)\n",
            "X_validate-> (2211, 18)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnLi2I4jj6W8",
        "outputId": "5e2315dc-29f2-4027-e0e3-6520a0f9476f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Fitting Random Forest model to all 4 subjects for final testing on 2 unseen subjects\n",
        "mask=total_data.Subject<=4\n",
        "X_final=total_data[columns][mask]\n",
        "Y_final=total_data.Activity[mask]\n",
        "classifier=RandomForestClassifier(n_estimators = 100, bootstrap='True',max_depth=1000,max_features=6,min_samples_leaf=1,min_samples_split=2, random_state = 42,max_samples=0.2,max_leaf_nodes=28)\n",
        "classifier.fit(X_final,Y_final)\n",
        "Y_predicted=classifier.predict(X_final)\n",
        "print(f'Training F1 score is: {f1_score(Y_final,Y_predicted,average=\"macro\"):.3f}')\n",
        "print(f'Training accuracy is: {accuracy_score(Y_final,Y_predicted):.3f}')\n",
        "# Saving model for later use\n",
        "pkl_file=\"/content/drive/MyDrive/Major_Project/Random_Forest_Model.pkl\"\n",
        "with open(pkl_file,'wb') as file:\n",
        "    pickle.dump(classifier,file) "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training F1 score is: 0.934\n",
            "Training accuracy is: 0.935\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}